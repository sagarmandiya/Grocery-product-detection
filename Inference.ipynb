{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGYQ6RL0f7ST"
      },
      "source": [
        "This notebooks takes the model trained in `Colabs/GroceryDataset_Model_Training.ipynb` notebook and runs inference with it to determine how many products are likely to be present inside a given shelf image. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBLZjxZLgP3u"
      },
      "source": [
        "## Inital setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NqU2APeK22f",
        "outputId": "896a6400-dd17-4c29-bda1-b74cd32bd072"
      },
      "source": [
        "# Which GPU?\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd4NZAq7LeH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28458553-ef92-4ad8-df9c-c73f5bd5e068"
      },
      "source": [
        "# Install TFOD API (TF 1)\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf \n",
        "print(tf.__version__)\n",
        "\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "% cd models/research\n",
        "!pip install --upgrade pip\n",
        "# Compile protos.\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "# Install TensorFlow Object Detection API.\n",
        "!cp object_detection/packages/tf1/setup.py .\n",
        "!python -m pip install --use-feature=2020-resolver ."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 60399, done.\u001b[K\n",
            "remote: Counting objects: 100% (178/178), done.\u001b[K\n",
            "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
            "remote: Total 60399 (delta 81), reused 141 (delta 59), pack-reused 60221\u001b[K\n",
            "Receiving objects: 100% (60399/60399), 573.89 MiB | 31.87 MiB/s, done.\n",
            "Resolving deltas: 100% (41973/41973), done.\n",
            "/content/models/research\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.2.4-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.2.4\n",
            "\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n",
            "Processing /content/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.24)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1661003 sha256=3cad1693a85785669a828856b3999d8242dc4013072980d31289dee01aab0910\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2bsv6pm2/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "Successfully built object-detection\n",
            "Installing collected packages: tf-slim, lvis, object-detection\n",
            "Successfully installed lvis-0.5.3 object-detection-0.1 tf-slim-1.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWprg3OxgS7o"
      },
      "source": [
        "## Gather trained model and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qim1npNwMqkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fba82df4-9eda-4909-f558-0705f963127a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYk-Cv_rruTn",
        "outputId": "499de3c5-3872-4c91-a306-a62cb182fdd0"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLYYyLh1Mt6e",
        "outputId": "08594649-3a55-4a77-d8f1-b62c9cc082f4"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/GroceryShelf/Product-Detection-From-Grocery-Shelf/models/research/object_detection/inference_graph/effdet/saved_model/*.pb .\n",
        "!ls -lh *.pb"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw------- 1 root root 23M Aug 21 13:04 saved_model.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6HgPU9HNx7X",
        "outputId": "175bfeea-1186-4ebb-c515-6ef36ffb0f78"
      },
      "source": [
        "%cd /content/drive/MyDrive/GroceryShelf/Product-Detection-From-Grocery-Shelf/\n",
        "!ls -lh ../Dataset/GroceryDataset_part1/ShelfImages/test | head -10"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/GroceryShelf/Product-Detection-From-Grocery-Shelf\n",
            "total 101M\n",
            "-rw------- 1 root root 1.6M Oct 23  2019 C1_P02_N1_S5_1.JPG\n",
            "-rw------- 1 root root 2.3M Oct 23  2019 C1_P02_N2_S2_1.JPG\n",
            "-rw------- 1 root root 2.3M Oct 23  2019 C1_P02_N2_S3_1.JPG\n",
            "-rw------- 1 root root 1.3M Oct 23  2019 C1_P03_N1_S2_1.JPG\n",
            "-rw------- 1 root root 1.6M Oct 23  2019 C1_P03_N1_S3_1.JPG\n",
            "-rw------- 1 root root 2.4M Oct 23  2019 C1_P03_N1_S4_1.JPG\n",
            "-rw------- 1 root root 1.4M Oct 23  2019 C1_P03_N1_S4_2.JPG\n",
            "-rw------- 1 root root 1.1M Oct 23  2019 C1_P03_N2_S2_1.JPG\n",
            "-rw------- 1 root root 1.7M Oct 23  2019 C1_P03_N2_S3_1.JPG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnDZPmbYgXOo"
      },
      "source": [
        "## Other imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75QByXOZN2Ea"
      },
      "source": [
        "from imutils import paths\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j007Jtg-gZ1C"
      },
      "source": [
        "## Image parsing utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuDYf5L8T9QU"
      },
      "source": [
        "def parse_image(image_path: str) -> np.ndarray:\n",
        "    \"\"\"Reads an image and adds a batch dimension.\"\"\"\n",
        "    image = plt.imread(image_path).astype(np.uint8)\n",
        "    image = np.expand_dims(image, 0)\n",
        "    return image"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4t2CTblgxJX"
      },
      "source": [
        "## Load test image paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlUGjLG8PWOD",
        "outputId": "16e4b1b9-12b7-4f40-87ee-1f558370d21b"
      },
      "source": [
        "test_image_paths = list(paths.list_images(\"../Dataset/GroceryDataset_part1/ShelfImages/test\"))\n",
        "test_image_paths[:5]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['../Dataset/GroceryDataset_part1/ShelfImages/test/C3_P01_N1_S5_1.JPG',\n",
              " '../Dataset/GroceryDataset_part1/ShelfImages/test/C4_P03_N1_S3_1.JPG',\n",
              " '../Dataset/GroceryDataset_part1/ShelfImages/test/C4_P04_N4_S2_1.JPG',\n",
              " '../Dataset/GroceryDataset_part1/ShelfImages/test/C4_P08_N1_S4_1.JPG',\n",
              " '../Dataset/GroceryDataset_part1/ShelfImages/test/C1_P03_N2_S2_1.JPG']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi4aiGlxgzOZ"
      },
      "source": [
        "## Load detection graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVKKup3o2w49"
      },
      "source": [
        "import tensorflow as tf\n",
        "import sys\n",
        "from tensorflow.python.platform import gfile\n",
        "from tensorflow.core.protobuf import saved_model_pb2\n",
        "from tensorflow.python.util import compat\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    model_filename ='./models/research/object_detection/inference_graph/effdet/saved_model/saved_model.pb'\n",
        "    with gfile.FastGFile(model_filename, 'rb') as f:\n",
        "        data = compat.as_bytes(f.read())\n",
        "        sm = saved_model_pb2.SavedModel()\n",
        "        sm.ParseFromString(data)\n",
        "        g_in = tf.import_graph_def(sm.meta_graphs[0].graph_def)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VKMB60rhbit"
      },
      "source": [
        "## Inference utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMKP9-KaPNzf"
      },
      "source": [
        "def run_inference_for_single_image(image, graph, min_threshold=0.6):\n",
        "    \"\"\"Runs detection graph on an image and parses the results.\"\"\"\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                \"num_detections\", \"detection_boxes\", \"detection_scores\",\n",
        "                \"detection_classes\"]:\n",
        "                tensor_name = key + \":0\"\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "                image_tensor = 'image_tensor:0'\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                    feed_dict={image_tensor: image})\n",
        "\n",
        "    # Post-process the results\n",
        "    output_dict[\"detection_scores\"] = output_dict[\"detection_scores\"][0]\n",
        "    mask = output_dict[\"detection_scores\"] > min_threshold\n",
        "\n",
        "    return output_dict[\"detection_scores\"][mask]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4m2vMjZhelj"
      },
      "source": [
        "## Run bulk inference and prepare JSON file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2n5B338eFOM"
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "image_to_products = {}\n",
        "for image_path in tqdm(test_image_paths):\n",
        "    image_name = image_path.split(\"/\")[-1]\n",
        "    image = parse_image(image_path)\n",
        "    num_products = len(run_inference_for_single_image(image, detection_graph))\n",
        "    image_to_products[image_name] = num_products\n",
        "\n",
        "json_string = json.dumps(image_to_products, indent=4) \n",
        "with open(\"image2products.json\", \"w\") as outfile: \n",
        "    outfile.write(json_string) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkBhSZZ3fhyY",
        "outputId": "c16304f5-03a1-4fa3-90cc-901e3e1d6e60"
      },
      "source": [
        "!head -10 image2products.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"C2_P03_N2_S3_1.JPG\": 22,\n",
            "    \"C1_P10_N1_S5_1.JPG\": 51,\n",
            "    \"C3_P01_N2_S3_2.JPG\": 17,\n",
            "    \"C4_P03_N1_S3_1.JPG\": 33,\n",
            "    \"C2_P04_N3_S2_1.JPG\": 21,\n",
            "    \"C3_P03_N2_S4_1.JPG\": 49,\n",
            "    \"C3_P04_N1_S5_1.JPG\": 40,\n",
            "    \"C4_P08_N2_S2_1.JPG\": 24,\n",
            "    \"C4_P03_N1_S4_1.JPG\": 45,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C62tMvqf0hb"
      },
      "source": [
        "## References\n",
        "* https://github.com/anirbankonar123/CorrosionDetector/blob/master/rust_localization.ipynb"
      ]
    }
  ]
}